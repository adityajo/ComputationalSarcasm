# SVM: This is a reimplementation of 'Harnessing context incongruity' by Joshi et al (2015)
#!/usr/bin/python

import sys

import re

# Sentiment wordlist load
f = open('/data/aa1/PhD_Sem8/AAAI17Demo/sentiwordlist','r')
sentiment_dict = {}

for line in f:
	words = line.split(' ')
	sentiment_dict[words[0]] = words[1]
	
# Interjection wordlist load
f = open('/data/aa1/PhD_Sem8/AAAI17Demo/interj_words','r')
interj_arr = []

for line in f:
	words = line.split(' ')
	
	if len(words)>0:
		interj_arr.append(words[0].strip())

#implicit phrases	
f = open('/data/aa1/PhD_Sem8/AAAI17Demo/implicit_phrases','r')
implicit_arr = []
implicit_dict = {}

for line in f:
	words = line.split(' ')
	
	if len(words)>0:
		implicit_arr.append(words[0].strip())	

# explicit flip features
def getExplicit(input,i_base):
	output = ''
	input = str(input).lower()
	words = re.findall(r"[\w']+|[.:,!?;]",input)
	abs_pos_score = 0
	flips = 0
	largest_sequence = 0
	curr_sequence = 0
	abs_neg_score = 0
	pos_score = 0
	neg_score = 0
	last_polarity = +1
	
	for word in words:
		if word.lower() in sentiment_dict:
					sentiment = sentiment_dict[word.lower()]
					
					if int(sentiment) == 1:
						#print(word+' found as positive')
						abs_pos_score += 1
						if last_polarity == 1:
							curr_sequence += 1
						else:
							flips += 1
							if largest_sequence > curr_sequence:
								largest_sequence = curr_sequence
							curr_sequence = 0
						last_polarity = 1						
						
					else:
						#print(word+' found as negative')
						abs_neg_score += 1
						if last_polarity == -1:
							curr_sequence += 1
						else:
							flips += 1
							if largest_sequence > curr_sequence:
								largest_sequence = curr_sequence
							curr_sequence = 0
						last_polarity = -1
						
						
	
	if (abs_pos_score > abs_neg_score):
		polarity = 1
	elif (abs_neg_score > abs_pos_score):
		polarity = 2
	else:
		polarity = 3 	

	output += str(i_base)+':'+str(abs_pos_score)+' '
	output += str(i_base+1)+':'+str(abs_neg_score)+' '
	output += str(i_base+2)+':'+str(polarity)+' '
	output += str(i_base+3)+':'+str(largest_sequence)+' '
	output += str(i_base+4)+':'+str(flips)
	return output.strip()
	

	
		

# Return count of interjections
def getInterjection(input,i_interj):
	output = ''
	count = 0
	input = str(input).lower()
	for i in range(0,len(interj_arr)):
		count += input.count(interj_arr[i])

	output = str(i_interj)+':'+str(count)
	return output


def getPunctuation(input,i_excl,i_quest,i_dotdot):
	output = ''
	input = str(input).strip()
	output += str(i_excl)+':'+str(input.count('!')) +' '
	output += str(i_quest)+':'+str(input.count('?'))+' '
	output += str(i_dotdot)+':'+str(input.count('...'))
	return output.strip()

def getImplicitFeatures(input):
	output = ''
	input = str(input).lower()
	
	word_count = {}
	word_ids = []
	words = re.findall(r"[\w']+|[.:,!?;]",input)
	
	for word in words:
		if word in implicit_dict:
			index = implicit_dict[word]
			if index in word_count:
				word_count[index] += 1
			else:
				word_count[index] = 1
				word_ids.append(index)

	word_ids = list(set(word_ids))
	word_ids.sort()
	
	for id in word_ids:
		output += str(id)+':'+str(word_count[id])+' '
	output = output.strip()
	
	return output


f = open(sys.argv[1],'r')
f_vocab = open(sys.argv[2],'r')
f_o2 = open(sys.argv[1] + '.o','w')
sep = str(sys.argv[3])
if sep == 'p':
	sep = '\t'
print(sep)
dict = dict()

for line in f_vocab:
	contents = line.split('\t')
	if len(contents) == 2:
		word1 = contents[0]
		word2 = contents[1]
		index = int(word2)
		dict[word1] = int(word2)
print('vocab loaded '+ str(index))
index += 1
for phrase in implicit_arr:
	implicit_dict[phrase] = index
	index += 1


i_excl = index + 1
i_quest = index + 2
i_dotdot = index + 3
i_interj = index + 4
i_base = index + 5

print(sep)
for line in f:
	s_line = ''
	contents = line.split(sep)
	pos_score = 0
	neg_score = 0
	
	if len(contents) == 2:
		word_ids = []
		dialogue = contents[0].lower()
		#dialogue = dialogue + ' '+ getActions(dialogue).lower()
		if len(dialogue) == 0:
			continue
		words = re.findall(r"[\w']+|[.,!?;]",dialogue)
		if (len(words)) <= 1:
			continue	
		
		s_punct = getPunctuation(line,i_excl,i_quest,i_dotdot)
		s_interj = getInterjection(line,i_interj)
		s_explicit = getExplicit(line,i_base)
		s_implicit = getImplicitFeatures(line)
		

		for word in words:
			if word in dict:
				index = dict[word]
				word_ids.append(index)
		
		if contents[1].strip().lower() == 'sarcasm' or contents[1].strip().lower() == 'sar':
			label = '+1'
		else:
			label = '-1'
	

		word_ids = list(set(word_ids))
		word_ids.sort()
		s_line = label+' '
		
		for id in word_ids:
			s_line += str(id)+':1 '
		
		s_line += s_implicit+' '+s_punct+' '+s_interj+' '+s_explicit

		
		s_line += ' # '+line
		s_line = s_line.strip()
		f_o2.write(s_line+'\n')
