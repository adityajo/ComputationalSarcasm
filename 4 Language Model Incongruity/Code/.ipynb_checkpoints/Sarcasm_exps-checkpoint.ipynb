{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from gensim.models import KeyedVectors as wv\n",
    "import operator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "mo = wv.load_word2vec_format('C:/Users/Samarth/Documents/Projects/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All words approach\n",
    "#Rule-based Approach using word2vec similarity and minimum as the measure\n",
    "\n",
    "def calc_val_w2v_all(file,v_threshold):\n",
    "    f = open (file,'r')\n",
    "    d_minval = dict()\n",
    "    d_predictedlabel = dict()\n",
    "    d_actuallabel = dict()\n",
    "    threshold = v_threshold\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "# 2\tNOT_SARCASM\ttest\tbacking\t0.285714285714\n",
    "    for line in f:\n",
    "        words = line.strip().split('\\t')\n",
    "        if len(words) != 5:\n",
    "            continue\n",
    "            \n",
    "        id = words[0].strip()\n",
    "#        if id not in acceptable:\n",
    "#            continue\n",
    "        label = words[1].strip()\n",
    "        d_actuallabel[id] = label.lower()\n",
    "\n",
    "        if id not in d_minval.keys():\n",
    "            d_minval[id] = '1'\n",
    "        word1 = words[2].strip()\n",
    "        word2 = words[3].strip()\n",
    "        #val = words[4].strip()\n",
    "        #if words[4] == 'None' or words[4] == '-1':\n",
    "        #    continue\n",
    "        \n",
    "        if word1.strip().lower() in mo.vocab and word2.strip().lower() in mo.vocab:\n",
    "            val = str(mo.similarity(word1,word2))\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        if val == -1:\n",
    "            continue\n",
    "        f_val = float(val)\n",
    "        if (float(d_minval[id]) > f_val):\n",
    "            d_minval[id] = str(f_val)\n",
    "\n",
    "   \n",
    "    for id in d_minval.keys():\n",
    "        if (float(d_minval[id]) < threshold):\n",
    "            d_predictedlabel[id] = 'sarcasm'\n",
    "        else:\n",
    "            d_predictedlabel[id] = 'not_sarcasm'\n",
    "\n",
    "        #print(d_predictedlabel[id] +' '+d_actuallabel[id])\n",
    "        if d_predictedlabel[id] == 'sarcasm' and d_actuallabel[id] == 'sarcasm':\n",
    "            tp += 1\n",
    "        elif d_predictedlabel[id] == 'not_sarcasm' and d_actuallabel[id] != 'sarcasm':\n",
    "            tn += 1\n",
    "        elif d_predictedlabel[id] == 'sarcasm' and d_actuallabel[id] != 'sarcasm':\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "    \n",
    "    \n",
    "    pprecision = float(tp)/float(tp+fp)\n",
    "    precall = float(tp)/float(tp+fn)\n",
    "    #pfscore = float(2*precision*recall)/float(precision+recall)\n",
    "    \n",
    "    nprecision = float(tn)/float(tn+fn)\n",
    "    nrecall = float(tn)/float(tn+fp)\n",
    "    #nfscore = float(2*precision*recall)/float(precision+recall)\n",
    "\n",
    "    total = tp + fp + fn + tn\n",
    "    aprecision = float(pprecision)*float(tp+fn)/float(total) + float(nprecision)*float(tn+fp)/float(total)\n",
    "    arecall = float(precall)*float(tp+fn)/float(total) + float(nrecall)*float(tn+fp)/float(total)\n",
    "    fscore = float(2*aprecision*arecall)/float(aprecision+arecall)\n",
    "    \n",
    "    #print(str(tp)+' '+str(fp)+' '+str(tn)+' '+str(fn))\n",
    "    #print('Precision : ' + str(float(tp)/float(tp+fp)))\n",
    "    #print('Recall : '+ str(float(tp)/float(tp+fn)))\n",
    "    #print('Accuracy : '+ str(float(tp+tn)/float(tp+tn+fp+fn)))\n",
    "    #print('F-score : '+ str(fscore))\n",
    "    return (str(threshold)+':'+str(aprecision)+':'+str(arecall)+':'+str(fscore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_val_wn_all(file,v_threshold):\n",
    "    f = open (file,'r')\n",
    "    d_minval = dict()\n",
    "    d_predictedlabel = dict()\n",
    "    d_actuallabel = dict()\n",
    "    threshold = v_threshold\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "# 2\tNOT_SARCASM\ttest\tbacking\t0.285714285714\n",
    "    for line in f:\n",
    "        words = line.strip().split('\\t')\n",
    "        if len(words) != 5:\n",
    "            continue\n",
    "        \n",
    "    \n",
    "        id = words[0].strip()\n",
    "        label = words[1].strip()\n",
    "        d_actuallabel[id] = label.lower()\n",
    "        \n",
    "#         if int(id) not in acceptable:\n",
    "#             continue\n",
    "            \n",
    "        if id not in d_minval.keys():\n",
    "            d_minval[id] = '1'\n",
    "        word1 = words[2].strip()\n",
    "        word2 = words[3].strip()\n",
    "        val = words[4].strip()\n",
    "        if words[4] == 'None' or words[4] == '-1':\n",
    "            continue\n",
    "        f_val = float(val)\n",
    "        if (float(d_minval[id]) > f_val):\n",
    "            d_minval[id] = str(f_val)\n",
    "\n",
    "   \n",
    "    for id in d_minval.keys():\n",
    "        if (float(d_minval[id]) < threshold):\n",
    "            d_predictedlabel[id] = 'sarcasm'\n",
    "        else:\n",
    "            d_predictedlabel[id] = 'not_sarcasm'\n",
    "\n",
    "        #print(d_predictedlabel[id] +' '+d_actuallabel[id])\n",
    "        if d_predictedlabel[id] == 'sarcasm' and d_actuallabel[id] == 'sarcasm':\n",
    "            tp += 1\n",
    "        elif d_predictedlabel[id] == 'not_sarcasm' and d_actuallabel[id] != 'sarcasm':\n",
    "            tn += 1\n",
    "        elif d_predictedlabel[id] == 'sarcasm' and d_actuallabel[id] != 'sarcasm':\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "    \n",
    "    \n",
    "    pprecision = float(tp)/float(tp+fp)\n",
    "    precall = float(tp)/float(tp+fn)\n",
    "    #pfscore = float(2*precision*recall)/float(precision+recall)\n",
    "    \n",
    "    nprecision = float(tn)/float(tn+fn)\n",
    "    nrecall = float(tn)/float(tn+fp)\n",
    "    #nfscore = float(2*precision*recall)/float(precision+recall)\n",
    "\n",
    "    total = tp + fp + fn + tn\n",
    "    aprecision = float(pprecision)*float(tp+fn)/float(total) + float(nprecision)*float(tn+fp)/float(total)\n",
    "    arecall = float(precall)*float(tp+fn)/float(total) + float(nrecall)*float(tn+fp)/float(total)\n",
    "    fscore = float(2*aprecision*arecall)/float(aprecision+arecall)\n",
    "    \n",
    "    #print(str(tp)+' '+str(fp)+' '+str(tn)+' '+str(fn))\n",
    "    #print('Precision : ' + str(float(tp)/float(tp+fp)))\n",
    "    #print('Recall : '+ str(float(tp)/float(tp+fn)))\n",
    "    #print('Accuracy : '+ str(float(tp+tn)/float(tp+tn+fp+fn)))\n",
    "    #print('F-score : '+ str(fscore))\n",
    "    return (str(threshold)+':'+str(aprecision)+':'+str(arecall)+':'+str(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.6882187854958497:0.7693333333333333:0.7265189978022202\n",
      "0.11:0.6768734612707694:0.7484444444444445:0.7108620184291868\n",
      "0.12:0.6765346217399071:0.7026666666666667:0.689353079261971\n",
      "0.13:0.6766909046131073:0.6711111111111111:0.673889457910721\n",
      "0.14:0.6716537264833223:0.6382222222222221:0.6545113440759646\n",
      "0.15:0.6704849169660267:0.6137777777777778:0.6408793840282356\n",
      "0.16:0.6750940450313551:0.6017777777777777:0.6363310505454035\n",
      "0.17:0.6755331407057176:0.5915555555555555:0.6307614984262467\n",
      "0.18:0.6756342296918768:0.5906666666666667:0.6302998276090723\n",
      "0.19:0.6753300349825089:0.5853333333333334:0.6271193252874674\n",
      "0.2:0.677820483734943:0.5857777777777778:0.6284468549666743\n",
      "0.21:0.6794750420905882:0.5817777777777778:0.6268425708402877\n",
      "0.22:0.6833484712530528:0.5808888888888889:0.6279667833033179\n",
      "0.23:0.6872082282549573:0.5737777777777777:0.625391254450602\n",
      "0.24:0.694373384164813:0.5644444444444444:0.6227036035784891\n",
      "0.25:0.694373384164813:0.5644444444444444:0.6227036035784891\n",
      "0.26:0.6940163316242098:0.5413333333333333:0.6082394075831439\n",
      "0.27:0.700431627361796:0.5186666666666667:0.5959987626447613\n",
      "0.28:0.7000718623969095:0.5177777777777778:0.5952814555081333\n",
      "0.29:0.7023383846953265:0.49688888888888894:0.5820150146389587\n",
      "0.3:0.7023383846953265:0.49688888888888894:0.5820150146389587\n",
      "0.31:0.7096302071186629:0.48311111111111116:0.5748610073270911\n",
      "0.32:0.7090689842579596:0.48177777777777775:0.5737323901237498\n",
      "0.33:0.7090689842579596:0.48177777777777775:0.5737323901237498\n",
      "0.34:0.7139044079593382:0.4715555555555555:0.5679577549134094\n",
      "0.35:0.7137152596568481:0.47111111111111115:0.5675754647087329\n",
      "0.36:0.7144225336809151:0.4693333333333334:0.5665058454774672\n",
      "0.37:0.7160592741776252:0.46266666666666667:0.5621268626398687\n",
      "0.38:0.7189655588680014:0.46044444444444443:0.5613716966922611\n",
      "0.39:0.7189857653747572:0.45866666666666667:0.5600545549989951\n",
      "0.4:0.7189857653747572:0.45866666666666667:0.5600545549989951\n",
      "0.41:0.7160784479844083:0.4502222222222222:0.5528496010893357\n",
      "0.42:0.7160784479844083:0.4502222222222222:0.5528496010893357\n",
      "0.43:0.7210090023672205:0.4484444444444444:0.5529634076286281\n",
      "0.44:0.7210090023672205:0.4484444444444444:0.5529634076286281\n",
      "0.45:0.7208632109114192:0.44622222222222224:0.5512281702076671\n",
      "0.46:0.7208632109114192:0.44622222222222224:0.5512281702076671\n",
      "0.47:0.7232761618704772:0.44400000000000006:0.5502290312446653\n",
      "0.48:0.721492454594574:0.44000000000000006:0.546635802524301\n",
      "0.49:0.7212921651607753:0.4395555555555556:0.546235260176023\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_all('tweets/tweets.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "file = 'tweets/tweets.o'\n",
    "file1 = 'tweets/tweets_train.o'\n",
    "file2 = 'tweets/tweets_test.o'\n",
    "f = open(file,'r')\n",
    "f1 = open(file1,'w')\n",
    "f2 = open(file2,'w')\n",
    "idx = list(range(2,2279))\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "for line in f:\n",
    "#     print(line[0])\n",
    "    if int(line.split('\\t')[0]) in set(idx[0:1139]):\n",
    "        f1.write(line)\n",
    "    else:\n",
    "        f2.write(line)\n",
    "f.close()\n",
    "f1.close()\n",
    "f2.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.7039899261777715:0.7804444444444445:0.7402483231373836\n",
      "0.11:0.6939257335989435:0.76:0.7254614803876531\n",
      "0.12:0.6932060367742361:0.7120000000000001:0.7024773382219011\n",
      "0.13:0.6929410032638001:0.6808888888888889:0.6868620816490469\n",
      "0.14:0.6908129652877874:0.6488888888888888:0.6691949497242622\n",
      "0.15:0.6962582633174222:0.6319999999999999:0.6625747937266216\n",
      "0.16:0.6998856620895759:0.6168888888888889:0.6557716172671748\n",
      "0.17:0.7025782939920872:0.6062222222222222:0.6508533109399215\n",
      "0.18:0.7032128694350918:0.6053333333333333:0.6506123962569398\n",
      "0.19:0.704806968340514:0.6017777777777777:0.6492302507438699\n",
      "0.2:0.7054548872732614:0.6008888888888889:0.6489869069843522\n",
      "0.21:0.7077558804295087:0.5964444444444444:0.6473500348895637\n",
      "0.22:0.7120646464646464:0.5973333333333334:0.6496725294889676\n",
      "0.23:0.7135819471009873:0.5875555555555556:0.6444653797270631\n",
      "0.24:0.7161815073815074:0.5715555555555556:0.6357470497842753\n",
      "0.25:0.7161815073815074:0.5715555555555556:0.6357470497842753\n",
      "0.26:0.7140187766714082:0.5413333333333333:0.6157988047459647\n",
      "0.27:0.7146897991229583:0.5146666666666666:0.5984057949848167\n",
      "0.28:0.7140150040810532:0.512888888888889:0.5969666641233792\n",
      "0.29:0.7149907765158907:0.49244444444444446:0.5832084895523123\n",
      "0.3:0.7149907765158907:0.49244444444444446:0.5832084895523123\n",
      "0.31:0.7270074092895091:0.4808888888888889:0.5788738417270765\n",
      "0.32:0.7263186417669176:0.4791111111111111:0.5773664216381293\n",
      "0.33:0.7263186417669176:0.4791111111111111:0.5773664216381293\n",
      "0.34:0.7277360370461528:0.46755555555555556:0.5693289055238788\n",
      "0.35:0.727383144096236:0.4666666666666667:0.5685616532664269\n",
      "0.36:0.7301124712995649:0.46577777777777774:0.5687313943267368\n",
      "0.37:0.7300835165108106:0.45777777777777773:0.5627189157310942\n",
      "0.38:0.7286438438438438:0.4542222222222222:0.5596005083821676\n",
      "0.39:0.7279160424667099:0.4524444444444444:0.5580355714852707\n",
      "0.4:0.7279160424667099:0.4524444444444444:0.5580355714852707\n",
      "0.41:0.7262158058328216:0.4444444444444444:0.551419731375859\n",
      "0.42:0.7262158058328216:0.4444444444444444:0.551419731375859\n",
      "0.43:0.7364124909222949:0.4444444444444444:0.554333773393575\n",
      "0.44:0.7364124909222949:0.4444444444444444:0.554333773393575\n",
      "0.45:0.7353257080610022:0.44177777777777777:0.5519490191953321\n",
      "0.46:0.7353257080610022:0.44177777777777777:0.5519490191953321\n",
      "0.47:0.7406785485545175:0.4417777777777778:0.5534501629215017\n",
      "0.48:0.7392445501367662:0.4382222222222222:0.5502548303381475\n",
      "0.49:0.7392445501367662:0.4382222222222222:0.5502548303381475\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_all('tweets/tweets_train.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.6726783694704906:0.7582222222222222:0.7128932521264454\n",
      "0.11:0.6600806016744715:0.7368888888888888:0.6963732056150431\n",
      "0.12:0.6604022949355496:0.6933333333333334:0.6764672731176762\n",
      "0.13:0.6608854490076926:0.6613333333333333:0.6611093153130332\n",
      "0.14:0.6529658673192376:0.6275555555555555:0.6400085938498289\n",
      "0.15:0.6449936502466512:0.5955555555555555:0.6192895048512823\n",
      "0.16:0.6507574712643678:0.5866666666666667:0.6170523182349195\n",
      "0.17:0.6491654766582214:0.5768888888888889:0.6108968102197871\n",
      "0.18:0.6487822255909802:0.5760000000000001:0.6102285845307529\n",
      "0.19:0.6465915040128961:0.5688888888888889:0.6052565297326267\n",
      "0.2:0.6508765274841555:0.5706666666666667:0.6081381978623634\n",
      "0.21:0.6519932972620197:0.5671111111111111:0.6065971720021718\n",
      "0.22:0.6552885185136657:0.5644444444444444:0.6064835091219417\n",
      "0.23:0.6614909560723514:0.56:0.6065291495757504\n",
      "0.24:0.673366080857402:0.5573333333333333:0.6098798099203383\n",
      "0.25:0.673366080857402:0.5573333333333333:0.6098798099203383\n",
      "0.26:0.6752726268268359:0.5413333333333333:0.600930118640553\n",
      "0.27:0.6870550500136718:0.5226666666666666:0.5936915372447363\n",
      "0.28:0.6870550500136718:0.5226666666666666:0.5936915372447363\n",
      "0.29:0.6903733035880276:0.5013333333333333:0.5808596491939657\n",
      "0.3:0.6903733035880276:0.5013333333333333:0.5808596491939657\n",
      "0.31:0.6931275382915939:0.48533333333333334:0.5709105948003905\n",
      "0.32:0.6927249484335086:0.48444444444444446:0.5701588145716776\n",
      "0.33:0.6927249484335086:0.48444444444444446:0.5701588145716776\n",
      "0.34:0.7007032425569011:0.47555555555555556:0.5665816405853032\n",
      "0.35:0.7007032425569011:0.47555555555555556:0.5665816405853032\n",
      "0.36:0.6994877237328491:0.4728888888888889:0.5642896129217987\n",
      "0.37:0.7027283286289667:0.46755555555555556:0.5615125330478152\n",
      "0.38:0.7097451725117971:0.4666666666666667:0.5630926225124343\n",
      "0.39:0.7104696174468599:0.4648888888888889:0.5620232963198301\n",
      "0.4:0.7104696174468599:0.4648888888888889:0.5620232963198301\n",
      "0.41:0.7063763712595486:0.456:0.554222596499134\n",
      "0.42:0.7063763712595486:0.456:0.554222596499134\n",
      "0.43:0.7062678789663431:0.4524444444444444:0.5515553285689829\n",
      "0.44:0.7062678789663431:0.4524444444444444:0.5515553285689829\n",
      "0.45:0.7070137200488493:0.45066666666666666:0.5504585206042936\n",
      "0.46:0.7070137200488493:0.45066666666666666:0.5504585206042936\n",
      "0.47:0.706497905578009:0.44622222222222224:0.5469759012952696\n",
      "0.48:0.7043300445295296:0.44177777777777777:0.5429809584022678\n",
      "0.49:0.7038909451257277:0.4408888888888889:0.5421788320765781\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_all('tweets/tweets_test.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.42074787003956005:0.4600280504908836:0.43951206632879397\n",
      "0.11:0.4456885484311036:0.4544179523141655:0.45001092066382203\n",
      "0.12:0.45606485098605176:0.45441795231416554:0.4552399121792336\n",
      "0.13:0.4587928361726248:0.45722300140252453:0.45800657362458497\n",
      "0.14:0.4593679619926976:0.4600280504908836:0.45969776928360306\n",
      "0.15:0.4491098967897419:0.45301542776998593:0.45105420825921827\n",
      "0.16:0.44716840661933277:0.45511921458625526:0.4511087800062075\n",
      "0.17:0.44518673804192327:0.4565217391304348:0.4507829948012257\n",
      "0.18:0.44518673804192327:0.4565217391304348:0.4507829948012257\n",
      "0.19:0.4480503375094086:0.46072931276297335:0.4543013788261133\n",
      "0.2:0.4489499294448662:0.4621318373071529:0.45544552272824396\n",
      "0.21:0.45592392300741136:0.46914446002805044:0.46243972142107675\n",
      "0.22:0.4522180901405853:0.4670406732117813:0.4595098783449878\n",
      "0.23:0.451273890774435:0.4684431977559607:0.45969828568899973\n",
      "0.24:0.449024389022576:0.4691444600280505:0.45886397637044285\n",
      "0.25:0.449024389022576:0.4691444600280505:0.45886397637044285\n",
      "0.26:0.44960227762560095:0.4740532959326788:0.4615041529954179\n",
      "0.27:0.45126453890437124:0.47685834502103785:0.46370855608795536\n",
      "0.28:0.4500575838798243:0.47615708274894814:0.46273960871135283\n",
      "0.29:0.450796528090185:0.4803646563814867:0.46511113849075364\n",
      "0.3:0.450796528090185:0.4803646563814867:0.46511113849075364\n",
      "0.31:0.44403887839278733:0.4803646563814867:0.46148803031407043\n",
      "0.32:0.43943975833343385:0.4782608695652174:0.4580291972193952\n",
      "0.33:0.43943975833343385:0.4782608695652174:0.4580291972193952\n",
      "0.34:0.4425967152736541:0.4817671809256662:0.4613520122996445\n",
      "0.35:0.44205477205461063:0.48176718092566617:0.4610574162271168\n",
      "0.36:0.4448238954926602:0.48387096774193544:0.46352656250753993\n",
      "0.37:0.44257326923991636:0.48387096774193544:0.462301663792476\n",
      "0.38:0.4373163575879883:0.48176718092566617:0.45846685298828393\n",
      "0.39:0.43553276828159704:0.4810659186535764:0.45716838626006023\n",
      "0.4:0.43553276828159704:0.4810659186535764:0.45716838626006023\n",
      "0.41:0.4351054491052607:0.48246844319775595:0.457564563285004\n",
      "0.42:0.4351054491052607:0.48246844319775595:0.457564563285004\n",
      "0.43:0.43920081509379894:0.48527349228611505:0.4610891003764564\n",
      "0.44:0.43920081509379894:0.48527349228611505:0.4610891003764564\n",
      "0.45:0.4402801350065074:0.48667601683029454:0.46231697577038355\n",
      "0.46:0.4402801350065074:0.48667601683029454:0.46231697577038355\n",
      "0.47:0.4375494464492897:0.4859747545582047:0.46049250168712436\n",
      "0.48:0.43935930661042766:0.4873772791023843:0.46212429012802286\n",
      "0.49:0.43935930661042766:0.4873772791023843:0.46212429012802286\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_all('iac/iaccorpus.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "file = 'iac/iaccorpus.o'\n",
    "file1 = 'iac/iaccorpus_train.o'\n",
    "file2 = 'iac/iaccorpus_test.o'\n",
    "f = open(file,'r')\n",
    "f1 = open(file1,'w')\n",
    "f2 = open(file2,'w')\n",
    "idx = list(range(1,1454))\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "for line in f:\n",
    "#     print(line[0])\n",
    "    if int(line.split('\\t')[0]) in set(idx[0:727]):\n",
    "        f1.write(line)\n",
    "    else:\n",
    "        f2.write(line)\n",
    "f.close()\n",
    "f1.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.4140998226051459:0.44817927170868344:0.43046609417698084\n",
      "0.11:0.44638465410513417:0.4481792717086835:0.44728016278270866\n",
      "0.12:0.4546068879328722:0.44957983193277307:0.45207938533472636\n",
      "0.13:0.4647529680826018:0.46078431372549017:0.4627601322152466\n",
      "0.14:0.4666359591965128:0.46638655462184875:0.466511223575236\n",
      "0.15:0.452982612043635:0.4565826330532213:0.4547754981825075\n",
      "0.16:0.45225416173795524:0.4593837535014006:0.4557910786351251\n",
      "0.17:0.4561890756302521:0.46638655462184875:0.46123145737370247\n",
      "0.18:0.4561890756302521:0.46638655462184875:0.46123145737370247\n",
      "0.19:0.46104765998732167:0.4733893557422969:0.4671370056064738\n",
      "0.2:0.4603531558033559:0.4733893557422969:0.46678025503828413\n",
      "0.21:0.46564896861907523:0.4789915966386555:0.4722260532843843\n",
      "0.22:0.46459237943246356:0.4789915966386554:0.4716821210489377\n",
      "0.23:0.4604245619816554:0.4775910364145658:0.46885071873753\n",
      "0.24:0.4518056111333422:0.47338935574229696:0.4623457213508955\n",
      "0.25:0.4518056111333422:0.47338935574229696:0.4623457213508955\n",
      "0.26:0.455140389489129:0.4803921568627451:0.46742547703903203\n",
      "0.27:0.4504299765121075:0.4789915966386554:0.4642719296735087\n",
      "0.28:0.4504299765121075:0.4789915966386554:0.4642719296735087\n",
      "0.29:0.4505105499305996:0.4831932773109244:0.4662799117515117\n",
      "0.3:0.4505105499305996:0.4831932773109244:0.4662799117515117\n",
      "0.31:0.44830074887097693:0.48599439775910364:0.46638720804308836\n",
      "0.32:0.4426779569126721:0.4831932773109244:0.46204915951040754\n",
      "0.33:0.4426779569126721:0.4831932773109244:0.46204915951040754\n",
      "0.34:0.44533655227351887:0.48739495798319327:0.4654175136079464\n",
      "0.35:0.44533655227351887:0.48739495798319327:0.4654175136079464\n",
      "0.36:0.4534154121511452:0.49299719887955185:0.472378591565665\n",
      "0.37:0.45452724544163103:0.4943977591036415:0.47362489242356587\n",
      "0.38:0.44819365804911837:0.4915966386554622:0.4688928935236757\n",
      "0.39:0.4449513138588769:0.4901960784313726:0.4664791688341909\n",
      "0.4:0.4449513138588769:0.4901960784313726:0.4664791688341909\n",
      "0.41:0.43144217776267874:0.484593837535014:0.4564759837058052\n",
      "0.42:0.43144217776267874:0.484593837535014:0.4564759837058052\n",
      "0.43:0.43350144618107833:0.48599439775910364:0.4582495411000018\n",
      "0.44:0.43350144618107833:0.48599439775910364:0.4582495411000018\n",
      "0.45:0.43265114225266676:0.48739495798319327:0.4583943896845183\n",
      "0.46:0.43265114225266676:0.48739495798319327:0.4583943896845183\n",
      "0.47:0.43108677682282726:0.48739495798319327:0.45751486069790237\n",
      "0.48:0.4377470432617491:0.4915966386554622:0.4631117190249823\n",
      "0.49:0.4377470432617491:0.4915966386554622:0.4631117190249823\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_all('iac/iaccorpus_train.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.42764253017062004:0.4719101123595506:0.44868710272455503\n",
      "0.11:0.44547562877364144:0.4606741573033708:0.45294743327797965\n",
      "0.12:0.4579977275596515:0.4592696629213483:0.45863281337138456\n",
      "0.13:0.45385491699254155:0.4536516853932584:0.45375327843654595\n",
      "0.14:0.45291391127816527:0.4536516853932584:0.4532824981309352\n",
      "0.15:0.44612375302766644:0.449438202247191:0.4477748442964777\n",
      "0.16:0.44309451482991613:0.4508426966292135:0.44693502712895095\n",
      "0.17:0.43460543272522245:0.4466292134831461:0.4405352954034257\n",
      "0.18:0.43460543272522245:0.4466292134831461:0.4405352954034257\n",
      "0.19:0.43531553432886083:0.44803370786516855:0.44158306504513084\n",
      "0.2:0.4379088128646768:0.4508426966292135:0.44428164219273425\n",
      "0.21:0.44668839961685025:0.4592696629213483:0.45289167171412514\n",
      "0.22:0.440038893690579:0.4550561797752809:0.44742156191302807\n",
      "0.23:0.44257064029527904:0.45926966292134835:0.4507655469872564\n",
      "0.24:0.4473333510280747:0.4648876404494382:0.4559415930934721\n",
      "0.25:0.4473333510280747:0.4648876404494382:0.4559415930934721\n",
      "0.26:0.44488579487888347:0.4676966292134832:0.45600612318773964\n",
      "0.27:0.453868555849306:0.4747191011235955:0.46405973898775316\n",
      "0.28:0.45131381844329477:0.473314606741573:0.4620524670779323\n",
      "0.29:0.4529959661363203:0.47752808988764045:0.46493864835733634\n",
      "0.3:0.4529959661363203:0.47752808988764045:0.46493864835733634\n",
      "0.31:0.4408821181815883:0.4747191011235955:0.4571753694331181\n",
      "0.32:0.43750253765331293:0.47331460674157305:0.45470453171013175\n",
      "0.33:0.43750253765331293:0.47331460674157305:0.45470453171013175\n",
      "0.34:0.4411404904040932:0.476123595505618:0.4579649408294461\n",
      "0.35:0.44003116892079047:0.47612359550561795:0.45736644160176904\n",
      "0.36:0.436419720133968:0.4747191011235955:0.4547644605213085\n",
      "0.37:0.4300322830811405:0.473314606741573:0.45063654559695604\n",
      "0.38:0.42610198789974074:0.47191011235955055:0.4478377004682549\n",
      "0.39:0.42610198789974074:0.47191011235955055:0.4478377004682549\n",
      "0.4:0.42610198789974074:0.47191011235955055:0.4478377004682549\n",
      "0.41:0.44172571741768785:0.4803370786516854:0.46022297304308224\n",
      "0.42:0.44172571741768785:0.4803370786516854:0.46022297304308224\n",
      "0.43:0.44905903615980586:0.48455056179775285:0.46613018702381187\n",
      "0.44:0.44905903615980586:0.48455056179775285:0.46613018702381187\n",
      "0.45:0.45207982325965423:0.4859550561797753:0.4684057719499202\n",
      "0.46:0.45207982325965423:0.4859550561797753:0.4684057719499202\n",
      "0.47:0.4477836769971602:0.4845505617977528:0.4654421627447397\n",
      "0.48:0.4433832762000139:0.48314606741573035:0.4624114448830267\n",
      "0.49:0.4433832762000139:0.48314606741573035:0.4624114448830267\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_all('iac/iaccorpus_test.o',i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP 50% words approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_list = list()\n",
    "\n",
    "def get_all_words(file,v_threshold):\n",
    "    f = open (file,'r')\n",
    "    d_allwords = dict()\n",
    "    d_topwords = dict()\n",
    "    old_id = 1\n",
    "    temp_list = list()\n",
    "    for line in f:\n",
    "        words = line.strip().split('\\t')\n",
    "        if len(words) != 5:\n",
    "            continue\n",
    "        \n",
    "        id = words[0].strip()\n",
    "       \n",
    "        if str(old_id) != id:\n",
    "            d_allwords[id] = temp_list\n",
    "            \n",
    "            #print(temp_list)\n",
    "            temp_list = list()\n",
    "            old_id = str(id)\n",
    "\n",
    "        word1 = words[2].strip()\n",
    "        temp_list.append(word1)\n",
    "\n",
    "    return d_allwords\n",
    "        \n",
    "answer = dict()\n",
    "\n",
    "def get_top_words(d_allwords):\n",
    "    for k in d_allwords.keys():\n",
    "        list1 = d_allwords[k]\n",
    "        wordsim = dict()\n",
    "        for i in range(0,len(list1)):\n",
    "            avg = 0\n",
    "            ssum = 0\n",
    "            for j in range(0,len(list1)):\n",
    "                if list1[i] != list1[j] and list1[i] in mo.vocab and list1[j] in mo.vocab:\n",
    "                    avg += mo.similarity(list1[i],list1[j])\n",
    "                    ssum += 1\n",
    "            \n",
    "            if ssum != 0:\n",
    "                avg = avg/ssum\n",
    "                wordsim[list1[i]] = avg\n",
    "                #print(str(i)+' '+str(wordsim[list1[i]])+' '+ str(list1[i]))\n",
    "        \n",
    "        x = wordsim\n",
    "        #x = {1: 2, 3: 4, 4: 3, 2: 1, 12: 0}\n",
    "        sorted_x = sorted(x.items(), key=operator.itemgetter(1))\n",
    "        l2 = list()\n",
    "        for i in range(0, int(len(sorted_x)/2)):\n",
    "            l2.append(sorted_x[i][0])\n",
    "        answer[k] = l2\n",
    "        #print(str(k)+' '+str(l2))\n",
    "        #print (sorted_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_allwords = get_all_words('tweets/tweets.o',1)\n",
    "get_top_words(d_allwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rule-based Approach using word2vec similarity, and top 50% words only and minimum as the measure\n",
    "\n",
    "def calc_val_w2v_top(file,v_threshold):\n",
    "    f = open (file,'r')\n",
    "    d_minval = dict()\n",
    "    d_predictedlabel = dict()\n",
    "    d_actuallabel = dict()\n",
    "    threshold = v_threshold\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "         \n",
    "# 2\tNOT_SARCASM\ttest\tbacking\t0.285714285714\n",
    "    for line in f:\n",
    "        words = line.strip().split('\\t')\n",
    "        if len(words) != 5:\n",
    "            continue\n",
    "            \n",
    "        id = words[0].strip()\n",
    "        label = words[1].strip()\n",
    "        d_actuallabel[id] = label.lower()\n",
    "\n",
    "        if id not in d_minval.keys():\n",
    "            d_minval[id] = '1'\n",
    "        \n",
    "        word1 = words[2].strip()\n",
    "        word2 = words[3].strip()\n",
    "        \n",
    "        if str(id) in answer.keys() and word1.strip() in answer[str(id)]:\n",
    "            val = words[4].strip()\n",
    "        elif str(id) not in answer.keys():\n",
    "            val = words[4].strip()\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        if words[4] == 'None' or words[4] == '-1':\n",
    "            continue\n",
    "        \n",
    "        if str(id) in answer.keys() and word1.strip() in answer[str(id)] and word1.strip().lower() in mo.vocab and word2.strip().lower() in mo.vocab:\n",
    "            val = str(mo.similarity(word1,word2))\n",
    "        elif str(id) not in answer.keys() and word1.strip().lower() in mo.vocab and word2.strip().lower() in mo.vocab:\n",
    "            val = str(mo.similarity(word1,word2))\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        if val == -1:\n",
    "            continue\n",
    "        f_val = float(val)\n",
    "        if (float(d_minval[id]) > f_val):\n",
    "            d_minval[id] = str(f_val)\n",
    "\n",
    "   \n",
    "    for id in d_minval.keys():\n",
    "        if (float(d_minval[id]) < threshold):\n",
    "            d_predictedlabel[id] = 'sarcasm'\n",
    "        else:\n",
    "            d_predictedlabel[id] = 'not_sarcasm'\n",
    "\n",
    "        #print(d_predictedlabel[id] +' '+d_actuallabel[id])\n",
    "        if d_predictedlabel[id] == 'sarcasm' and d_actuallabel[id] == 'sarcasm':\n",
    "            tp += 1\n",
    "        elif d_predictedlabel[id] != 'sarcasm' and d_actuallabel[id] != 'sarcasm':\n",
    "            tn += 1\n",
    "        elif d_predictedlabel[id] == 'sarcasm' and d_actuallabel[id] != 'sarcasm':\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "    if float(tp+fp)==0 or float(tp+fn) == 0 or float (tn+fn) == 0 or float(tn+fp) == 0:\n",
    "        return ('none')\n",
    "    \n",
    "\n",
    "    #print(str(tp)+' '+str(fp)+' '+str(tn)+' '+str(fn))\n",
    "    pprecision = float(tp)/float(tp+fp)\n",
    "    precall = float(tp)/float(tp+fn)\n",
    "    #pfscore = float(2*precision*recall)/float(precision+recall)\n",
    "    \n",
    "    nprecision = float(tn)/float(tn+fn)\n",
    "    nrecall = float(tn)/float(tn+fp)\n",
    "    #nfscore = float(2*precision*recall)/float(precision+recall)\n",
    "\n",
    "    total = tp + fp + fn + tn\n",
    "    aprecision = float(pprecision)*float(tp+fn)/float(total) + float(nprecision)*float(tn+fp)/float(total)\n",
    "    arecall = float(precall)*float(tp+fn)/float(total) + float(nrecall)*float(tn+fp)/float(total)\n",
    "    fscore = float(2*aprecision*arecall)/float(aprecision+arecall)\n",
    "    return (str(threshold)+':'+str(aprecision)+':'+str(arecall)+':'+str(fscore))\n",
    "#     return (str(threshold)+':'+str(pprecision)+':'+str(precall)+':'+str(nprecision)+':'+str(nrecall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rule-based Approach using wordnet similarity, and top 50% words only and minimum as the measure\n",
    "#Class-wise statistics\n",
    "\n",
    "def calc_val_wn_top(file,v_threshold):\n",
    "    f = open (file,'r')\n",
    "    d_minval = dict()\n",
    "    d_predictedlabel = dict()\n",
    "    d_actuallabel = dict()\n",
    "    threshold = v_threshold\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "         \n",
    "# 2\tNOT_SARCASM\ttest\tbacking\t0.285714285714\n",
    "    for line in f:\n",
    "        words = line.strip().split('\\t')\n",
    "        if len(words) != 5:\n",
    "            continue\n",
    "            \n",
    "        id = words[0].strip()\n",
    "        label = words[1].strip()\n",
    "        d_actuallabel[id] = label.lower()\n",
    "\n",
    "        if id not in d_minval.keys():\n",
    "            d_minval[id] = '1'\n",
    "        \n",
    "        word1 = words[2].strip()\n",
    "        word2 = words[3].strip()\n",
    "        \n",
    "        if str(id) in answer.keys() and word1.strip() in answer[str(id)]:\n",
    "            val = words[4].strip()\n",
    "        elif str(id) not in answer.keys():\n",
    "            val = words[4].strip()\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        if words[4] == 'None' or words[4] == '-1':\n",
    "            continue\n",
    "        \n",
    "#        if str(id) in answer.keys() and word1.strip() in answer[str(id)] and word1.strip().lower() in mo.vocab and word2.strip().lower() in mo.vocab:\n",
    "#            val = str(mo.similarity(word1,word2))\n",
    "#        elif str(id) not in answer.keys() and word1.strip().lower() in mo.vocab and word2.strip().lower() in mo.vocab:\n",
    "#            val = str(mo.similarity(word1,word2))\n",
    "\n",
    "#        else:\n",
    "#            continue\n",
    "            \n",
    "        if val == -1:\n",
    "            continue\n",
    "        f_val = float(val)\n",
    "        if (float(d_minval[id]) > f_val):\n",
    "            d_minval[id] = str(f_val)\n",
    "\n",
    "   \n",
    "    for id in d_minval.keys():\n",
    "        if (float(d_minval[id]) < threshold):\n",
    "            d_predictedlabel[id] = 'sarcasm'\n",
    "        else:\n",
    "            d_predictedlabel[id] = 'not_sarcasm'\n",
    "\n",
    "        #print(d_predictedlabel[id] +' '+d_actuallabel[id])\n",
    "        if d_predictedlabel[id] == 'sarcasm' and d_actuallabel[id] == 'sarcasm':\n",
    "            tp += 1\n",
    "        elif d_predictedlabel[id] == 'not_sarcasm' and d_actuallabel[id] != 'sarcasm':\n",
    "            tn += 1\n",
    "        elif d_predictedlabel[id] == 'sarcasm' and d_actuallabel[id] != 'sarcasm':\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "    if float(tp+fp)==0 or float(tp+fn) == 0 or float (tn+fn) == 0 or float(tn+fp) == 0:\n",
    "        return ('none')\n",
    "        \n",
    "\n",
    "    #print(str(tp)+' '+str(fp)+' '+str(tn)+' '+str(fn))\n",
    "    pprecision = float(tp)/float(tp+fp)\n",
    "    precall = float(tp)/float(tp+fn)\n",
    "    #pfscore = float(2*precision*recall)/float(precision+recall)\n",
    "    \n",
    "    nprecision = float(tn)/float(tn+fn)\n",
    "    nrecall = float(tn)/float(tn+fp)\n",
    "    #nfscore = float(2*precision*recall)/float(precision+recall)\n",
    "\n",
    "    total = tp + fp + fn + tn\n",
    "    aprecision = float(pprecision)*float(tp+fn)/float(total) + float(nprecision)*float(tn+fp)/float(total)\n",
    "    arecall = float(precall)*float(tp+fn)/float(total) + float(nrecall)*float(tn+fp)/float(total)\n",
    "    fscore = float(2*aprecision*arecall)/float(aprecision+arecall)\n",
    "    return (str(threshold)+':'+str(aprecision)+':'+str(arecall)+':'+str(fscore))\n",
    "#     return (str(threshold)+':'+str(pprecision)+':'+str(precall)+':'+str(nprecision)+':'+str(nrecall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.6611133867616503:0.7773333333333333:0.7145283387469348\n",
      "0.11:0.6611133867616503:0.7773333333333333:0.7145283387469348\n",
      "0.12:0.6611133867616503:0.7773333333333333:0.7145283387469348\n",
      "0.13:0.6611526414907325:0.7764444444444445:0.7141754813467899\n",
      "0.14:0.6611526414907325:0.7764444444444445:0.7141754813467899\n",
      "0.15:0.6611526414907325:0.7764444444444445:0.7141754813467899\n",
      "0.16:0.6611526414907325:0.7764444444444445:0.7141754813467899\n",
      "0.17:0.6611526414907325:0.7764444444444445:0.7141754813467899\n",
      "0.18:0.6549151668402002:0.776:0.7103344506302951\n",
      "0.19:0.6499097222222222:0.7755555555555556:0.707195192386285\n",
      "0.2:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.21:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.22:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.23:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.24:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.25:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.26:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.27:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.28:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.29:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.3:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.31:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.32:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.33:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.34:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.35:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.36:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.37:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.38:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.39:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.4:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.41:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.42:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.43:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.44:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.45:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.46:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.47:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.48:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.49:0.6800212491311688:0.7764444444444444:0.7250410680059813\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_w2v_top('tweets/tweets.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.6243036773428233:0.7893333333333333:0.6971856267593972\n",
      "0.11:0.6243036773428233:0.7893333333333333:0.6971856267593972\n",
      "0.12:0.6243036773428233:0.7893333333333333:0.6971856267593972\n",
      "0.13:0.6241559315326012:0.7884444444444444:0.696746631323172\n",
      "0.14:0.6241559315326012:0.7884444444444444:0.696746631323172\n",
      "0.15:0.6241559315326012:0.7884444444444444:0.696746631323172\n",
      "0.16:0.6241559315326012:0.7884444444444444:0.696746631323172\n",
      "0.17:0.6241559315326012:0.7884444444444444:0.696746631323172\n",
      "0.18:0.6241559315326012:0.7884444444444444:0.696746631323172\n",
      "0.19:0.6240079223608636:0.7875555555555556:0.6963071992927787\n",
      "0.2:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.21:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.22:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.23:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.24:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.25:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.26:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.27:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.28:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.29:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.3:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.31:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.32:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.33:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.34:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.35:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.36:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.37:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.38:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.39:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.4:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.41:0.6770090197244524:0.7884444444444445:0.7284898681422805\n",
      "0.42:0.7090333333333333:0.7893333333333333:0.7470316270309151\n",
      "0.43:0.7090333333333333:0.7893333333333333:0.7470316270309151\n",
      "0.44:0.7090333333333333:0.7893333333333333:0.7470316270309151\n",
      "0.45:0.7090333333333333:0.7893333333333333:0.7470316270309151\n",
      "0.46:0.7090333333333333:0.7893333333333333:0.7470316270309151\n",
      "0.47:0.7090333333333333:0.7893333333333333:0.7470316270309151\n",
      "0.48:0.7090333333333333:0.7893333333333333:0.7470316270309151\n",
      "0.49:0.7090333333333333:0.7893333333333333:0.7470316270309151\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_w2v_top('tweets/tweets_train.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.6652263814616757:0.7653333333333334:0.7117772417047125\n",
      "0.11:0.6652263814616757:0.7653333333333334:0.7117772417047125\n",
      "0.12:0.6652263814616757:0.7653333333333334:0.7117772417047125\n",
      "0.13:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.14:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.15:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.16:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.17:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.18:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.19:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.2:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.21:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.22:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.23:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.24:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.25:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.26:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.27:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.28:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.29:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.3:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.31:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.32:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.33:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.34:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.35:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.36:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.37:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.38:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.39:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.4:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.41:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.42:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.43:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.44:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.45:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.46:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.47:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.48:0.654139307720703:0.7635555555555555:0.7046251142691465\n",
      "0.49:0.654139307720703:0.7635555555555555:0.7046251142691465\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_w2v_top('tweets/tweets_test.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n",
      "none\n",
      "0.12:0.8276768934341188:0.7786666666666667:0.8024241185950666\n",
      "0.13:0.8276768934341188:0.7786666666666667:0.8024241185950666\n",
      "0.14:0.8279464215104784:0.7791111111111112:0.8027867619041722\n",
      "0.15:0.7539439252336448:0.7786666666666667:0.7661058930662158\n",
      "0.16:0.7539439252336448:0.7786666666666667:0.7661058930662158\n",
      "0.17:0.7539439252336448:0.7786666666666667:0.7661058930662158\n",
      "0.18:0.7539439252336448:0.7786666666666667:0.7661058930662158\n",
      "0.19:0.7539439252336448:0.7786666666666667:0.7661058930662158\n",
      "0.2:0.7539439252336448:0.7786666666666667:0.7661058930662158\n",
      "0.21:0.7539439252336448:0.7786666666666667:0.7661058930662158\n",
      "0.22:0.7539439252336448:0.7786666666666667:0.7661058930662158\n",
      "0.23:0.7393520415738679:0.7786666666666666:0.7585002563938041\n",
      "0.24:0.7011796842380882:0.7777777777777778:0.7374951486248679\n",
      "0.25:0.7011796842380882:0.7777777777777778:0.7374951486248679\n",
      "0.26:0.7011796842380882:0.7777777777777778:0.7374951486248679\n",
      "0.27:0.6892219744275945:0.7773333333333333:0.7306307671496561\n",
      "0.28:0.6892219744275945:0.7773333333333333:0.7306307671496561\n",
      "0.29:0.7048936486687492:0.7777777777777778:0.7395443196004995\n",
      "0.3:0.7048936486687492:0.7777777777777778:0.7395443196004995\n",
      "0.31:0.7174853174603175:0.7782222222222223:0.7466205837062184\n",
      "0.32:0.7174853174603175:0.7782222222222223:0.7466205837062184\n",
      "0.33:0.7174853174603175:0.7782222222222223:0.7466205837062184\n",
      "0.34:0.7174853174603175:0.7782222222222223:0.7466205837062184\n",
      "0.35:0.7174853174603175:0.7782222222222223:0.7466205837062184\n",
      "0.36:0.7174853174603175:0.7782222222222223:0.7466205837062184\n",
      "0.37:0.7073278565015947:0.7777777777777778:0.7408818277860472\n",
      "0.38:0.7073278565015947:0.7777777777777778:0.7408818277860472\n",
      "0.39:0.7073278565015947:0.7777777777777778:0.7408818277860472\n",
      "0.4:0.7073278565015947:0.7777777777777778:0.7408818277860472\n",
      "0.41:0.6988504617217755:0.7773333333333333:0.7360055851194962\n",
      "0.42:0.6988504617217755:0.7773333333333333:0.7360055851194962\n",
      "0.43:0.6988504617217755:0.7773333333333333:0.7360055851194962\n",
      "0.44:0.6988504617217755:0.7773333333333333:0.7360055851194962\n",
      "0.45:0.6988504617217755:0.7773333333333333:0.7360055851194962\n",
      "0.46:0.6988504617217755:0.7773333333333333:0.7360055851194962\n",
      "0.47:0.6988504617217755:0.7773333333333333:0.7360055851194962\n",
      "0.48:0.6988504617217755:0.7773333333333333:0.7360055851194962\n",
      "0.49:0.6988504617217755:0.7773333333333333:0.7360055851194962\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_top('tweets/tweets.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n",
      "none\n",
      "none\n",
      "none\n",
      "0.14:0.8347844998022933:0.7911111111111112:0.81236124723397\n",
      "0.15:0.8347844998022933:0.7911111111111112:0.81236124723397\n",
      "0.16:0.8347844998022933:0.7911111111111112:0.81236124723397\n",
      "0.17:0.8347844998022933:0.7911111111111112:0.81236124723397\n",
      "0.18:0.8347844998022933:0.7911111111111112:0.81236124723397\n",
      "0.19:0.8347844998022933:0.7911111111111112:0.81236124723397\n",
      "0.2:0.8347844998022933:0.7911111111111112:0.81236124723397\n",
      "0.21:0.8347844998022933:0.7911111111111112:0.81236124723397\n",
      "0.22:0.8347844998022933:0.7911111111111112:0.81236124723397\n",
      "0.23:0.7652683699742524:0.7911111111111111:0.7779751889896758\n",
      "0.24:0.7301583903260978:0.7902222222222222:0.7590038718141733\n",
      "0.25:0.7301583903260978:0.7902222222222222:0.7590038718141733\n",
      "0.26:0.7301583903260978:0.7902222222222222:0.7590038718141733\n",
      "0.27:0.7301583903260978:0.7902222222222222:0.7590038718141733\n",
      "0.28:0.7301583903260978:0.7902222222222222:0.7590038718141733\n",
      "0.29:0.7301583903260978:0.7902222222222222:0.7590038718141733\n",
      "0.3:0.7301583903260978:0.7902222222222222:0.7590038718141733\n",
      "0.31:0.7516944444444444:0.7911111111111111:0.7708992556049684\n",
      "0.32:0.7516944444444444:0.7911111111111111:0.7708992556049684\n",
      "0.33:0.7516944444444444:0.7911111111111111:0.7708992556049684\n",
      "0.34:0.7516944444444444:0.7911111111111111:0.7708992556049684\n",
      "0.35:0.7516944444444444:0.7911111111111111:0.7708992556049684\n",
      "0.36:0.7516944444444444:0.7911111111111111:0.7708992556049684\n",
      "0.37:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.38:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.39:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.4:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.41:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.42:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.43:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.44:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.45:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.46:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.47:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.48:0.7305697547413366:0.7902222222222223:0.7592260661878497\n",
      "0.49:0.7305697547413366:0.7902222222222223:0.7592260661878497\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_top('tweets/tweets_train.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n",
      "none\n",
      "0.12:0.8213965994464215:0.7671111111111112:0.7933262821155335\n",
      "0.13:0.8213965994464215:0.7671111111111112:0.7933262821155335\n",
      "0.14:0.8213965994464215:0.7671111111111112:0.7933262821155335\n",
      "0.15:0.7043486692391412:0.7662222222222222:0.7339837959493014\n",
      "0.16:0.7043486692391412:0.7662222222222222:0.7339837959493014\n",
      "0.17:0.7043486692391412:0.7662222222222222:0.7339837959493014\n",
      "0.18:0.7043486692391412:0.7662222222222222:0.7339837959493014\n",
      "0.19:0.7043486692391412:0.7662222222222222:0.7339837959493014\n",
      "0.2:0.7043486692391412:0.7662222222222222:0.7339837959493014\n",
      "0.21:0.7043486692391412:0.7662222222222222:0.7339837959493014\n",
      "0.22:0.7043486692391412:0.7662222222222222:0.7339837959493014\n",
      "0.23:0.7043486692391412:0.7662222222222222:0.7339837959493014\n",
      "0.24:0.6652263814616757:0.7653333333333334:0.7117772417047125\n",
      "0.25:0.6652263814616757:0.7653333333333334:0.7117772417047125\n",
      "0.26:0.6652263814616757:0.7653333333333334:0.7117772417047125\n",
      "0.27:0.645585290910893:0.7644444444444445:0.7000052221274803\n",
      "0.28:0.645585290910893:0.7644444444444445:0.7000052221274803\n",
      "0.29:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.3:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.31:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.32:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.33:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.34:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.35:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.36:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.37:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.38:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.39:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.4:0.6811761904761905:0.7653333333333333:0.7208066533450528\n",
      "0.41:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.42:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.43:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.44:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.45:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.46:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.47:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.48:0.665431436798729:0.7644444444444445:0.7115098194078324\n",
      "0.49:0.665431436798729:0.7644444444444445:0.7115098194078324\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_top('tweets/tweets_test.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_allwords = get_all_words('iac/iaccorpus.o',1)\n",
    "get_top_words(d_allwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.32616377323705636:0.47826086956521735:0.38783339422725616\n",
      "0.11:0.30549429482984386:0.4761570827489481:0.37219475688306464\n",
      "0.12:0.29590843305183373:0.47475455820476853:0.36457927523812467\n",
      "0.13:0.2919294558201255:0.4740532959326788:0.3613400442625755\n",
      "0.14:0.3174284260912066:0.4747545582047686:0.3804691470986231\n",
      "0.15:0.3127158080669846:0.4740532959326788:0.37684235120770193\n",
      "0.16:0.33464145846592147:0.4747545582047686:0.39257064403277553\n",
      "0.17:0.348722144304192:0.4747545582047686:0.4020937739973396\n",
      "0.18:0.348722144304192:0.4747545582047686:0.4020937739973396\n",
      "0.19:0.3823327841279305:0.4761570827489481:0.42411790786051917\n",
      "0.2:0.3823327841279305:0.4761570827489481:0.42411790786051917\n",
      "0.21:0.37612352627305884:0.4754558204768583:0.41999637606834384\n",
      "0.22:0.37612352627305884:0.4754558204768583:0.41999637606834384\n",
      "0.23:0.3703778339472589:0.4747545582047686:0.41612075588942554\n",
      "0.24:0.3703778339472589:0.4747545582047686:0.41612075588942554\n",
      "0.25:0.3736099253580544:0.4740532959326788:0.41788062065371107\n",
      "0.26:0.3736099253580544:0.4740532959326788:0.41788062065371107\n",
      "0.27:0.3736099253580544:0.4740532959326788:0.41788062065371107\n",
      "0.28:0.3736099253580544:0.4740532959326788:0.41788062065371107\n",
      "0.29:0.3640501289417726:0.4726507713884993:0.41130247188808006\n",
      "0.3:0.3640501289417726:0.4726507713884993:0.41130247188808006\n",
      "0.31:0.3640501289417726:0.4726507713884993:0.41130247188808006\n",
      "0.32:0.3597010127555281:0.47194950911640954:0.40825012895209273\n",
      "0.33:0.3517375266351644:0.47054698457223:0.4025590419453414\n",
      "0.34:0.36319505951834796:0.47124824684431976:0.41022567682064204\n",
      "0.35:0.3699634494347916:0.47124824684431976:0.4145083281979847\n",
      "0.36:0.3699634494347916:0.47124824684431976:0.4145083281979847\n",
      "0.37:0.3699634494347916:0.47124824684431976:0.4145083281979847\n",
      "0.38:0.3699634494347916:0.47124824684431976:0.4145083281979847\n",
      "0.39:0.3699634494347916:0.47124824684431976:0.4145083281979847\n",
      "0.4:0.36610536080066225:0.47054698457223:0.4118073044633611\n",
      "0.41:0.36610536080066225:0.47054698457223:0.4118073044633611\n",
      "0.42:0.36243551668288077:0.4698457223001402:0.40920969774873567\n",
      "0.43:0.35893977846993275:0.46914446002805044:0.4067088847344962\n",
      "0.44:0.35893977846993275:0.46914446002805044:0.4067088847344962\n",
      "0.45:0.35893977846993275:0.46914446002805044:0.4067088847344962\n",
      "0.46:0.35893977846993275:0.46914446002805044:0.4067088847344962\n",
      "0.47:0.35893977846993275:0.46914446002805044:0.4067088847344962\n",
      "0.48:0.35893977846993275:0.46914446002805044:0.4067088847344962\n",
      "0.49:0.35560538686991516:0.46844319775596077:0.4042987942032995\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_w2v_top('iac/iaccorpus.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.3540369668994358:0.469187675070028:0.4035588171680418\n",
      "0.11:0.3272838613583656:0.4677871148459384:0.3851207698999871\n",
      "0.12:0.296403709998851:0.4649859943977591:0.3620316193958096\n",
      "0.13:0.296403709998851:0.4649859943977591:0.3620316193958096\n",
      "0.14:0.296403709998851:0.4649859943977591:0.3620316193958096\n",
      "0.15:0.2866193927996128:0.4635854341736695:0.35423012722986424\n",
      "0.16:0.3382667487798902:0.4649859943977591:0.39163090792788674\n",
      "0.17:0.3648911265010336:0.46498599439775906:0.4089021350998145\n",
      "0.18:0.3648911265010336:0.46498599439775906:0.4089021350998145\n",
      "0.19:0.3972064609319511:0.4663865546218487:0.42902559296127113\n",
      "0.2:0.3972064609319511:0.4663865546218487:0.42902559296127113\n",
      "0.21:0.38330995736383:0.46498599439775906:0.4202159902266636\n",
      "0.22:0.38330995736383:0.46498599439775906:0.4202159902266636\n",
      "0.23:0.3713465386154462:0.46358543417366943:0.41237095222945125\n",
      "0.24:0.3713465386154462:0.46358543417366943:0.41237095222945125\n",
      "0.25:0.36092937890463767:0.4621848739495798:0.4053291482082622\n",
      "0.26:0.36092937890463767:0.4621848739495798:0.4053291482082622\n",
      "0.27:0.36092937890463767:0.4621848739495798:0.4053291482082622\n",
      "0.28:0.36092937890463767:0.4621848739495798:0.4053291482082622\n",
      "0.29:0.36092937890463767:0.4621848739495798:0.4053291482082622\n",
      "0.3:0.36092937890463767:0.4621848739495798:0.4053291482082622\n",
      "0.31:0.36092937890463767:0.4621848739495798:0.4053291482082622\n",
      "0.32:0.36092937890463767:0.4621848739495798:0.4053291482082622\n",
      "0.33:0.3517683577729086:0.46078431372549017:0.3989632845039555\n",
      "0.34:0.3517683577729086:0.46078431372549017:0.3989632845039555\n",
      "0.35:0.34364161733559995:0.45938375350140054:0.39317157779554945\n",
      "0.36:0.34364161733559995:0.45938375350140054:0.39317157779554945\n",
      "0.37:0.34364161733559995:0.45938375350140054:0.39317157779554945\n",
      "0.38:0.34364161733559995:0.45938375350140054:0.39317157779554945\n",
      "0.39:0.34364161733559995:0.45938375350140054:0.39317157779554945\n",
      "0.4:0.3363766004486085:0.4579831932773109:0.38787166932160694\n",
      "0.41:0.3363766004486085:0.4579831932773109:0.38787166932160694\n",
      "0.42:0.32983707682239877:0.4565826330532213:0.3829962019592998\n",
      "0.43:0.32983707682239877:0.4565826330532213:0.3829962019592998\n",
      "0.44:0.32983707682239877:0.4565826330532213:0.3829962019592998\n",
      "0.45:0.32983707682239877:0.4565826330532213:0.3829962019592998\n",
      "0.46:0.32983707682239877:0.4565826330532213:0.3829962019592998\n",
      "0.47:0.32983707682239877:0.4565826330532213:0.3829962019592998\n",
      "0.48:0.32983707682239877:0.4565826330532213:0.3829962019592998\n",
      "0.49:0.32983707682239877:0.4565826330532213:0.3829962019592998\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_w2v_top('iac/iaccorpus_train.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.3148640187607436:0.48735955056179775:0.3825666373799114\n",
      "0.11:0.29809644061566:0.4845505617977528:0.36911352710689965\n",
      "0.12:0.29809644061566:0.4845505617977528:0.36911352710689965\n",
      "0.13:0.29211882582669096:0.4831460674157303:0.3640976475175792\n",
      "0.14:0.33383215864101917:0.4845505617977528:0.3953127454326903\n",
      "0.15:0.33383215864101917:0.4845505617977528:0.3953127454326903\n",
      "0.16:0.33383215864101917:0.4845505617977528:0.3953127454326903\n",
      "0.17:0.33383215864101917:0.4845505617977528:0.3953127454326903\n",
      "0.18:0.33383215864101917:0.4845505617977528:0.3953127454326903\n",
      "0.19:0.36865168539325843:0.48595505617977525:0.41925283705649297\n",
      "0.2:0.36865168539325843:0.48595505617977525:0.41925283705649297\n",
      "0.21:0.36865168539325843:0.48595505617977525:0.41925283705649297\n",
      "0.22:0.36865168539325843:0.48595505617977525:0.41925283705649297\n",
      "0.23:0.36865168539325843:0.48595505617977525:0.41925283705649297\n",
      "0.24:0.36865168539325843:0.48595505617977525:0.41925283705649297\n",
      "0.25:0.38669530463097956:0.4859550561797753:0.4306800224360534\n",
      "0.26:0.38669530463097956:0.4859550561797753:0.4306800224360534\n",
      "0.27:0.38669530463097956:0.4859550561797753:0.4306800224360534\n",
      "0.28:0.38669530463097956:0.4859550561797753:0.4306800224360534\n",
      "0.29:0.3679129536355418:0.48314606741573035:0.4177282475209414\n",
      "0.3:0.3679129536355418:0.48314606741573035:0.4177282475209414\n",
      "0.31:0.3679129536355418:0.48314606741573035:0.4177282475209414\n",
      "0.32:0.36011354828893:0.4817415730337079:0.41214138354566837\n",
      "0.33:0.3531392675582036:0.4803370786516854:0.4070322688998966\n",
      "0.34:0.37418452498286914:0.48174157303370785:0.4212051533136614\n",
      "0.35:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.36:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.37:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.38:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.39:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.4:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.41:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.42:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.43:0.38557189083213894:0.4817415730337079:0.4283249757916506\n",
      "0.44:0.38557189083213894:0.4817415730337079:0.4283249757916506\n",
      "0.45:0.38557189083213894:0.4817415730337079:0.4283249757916506\n",
      "0.46:0.38557189083213894:0.4817415730337079:0.4283249757916506\n",
      "0.47:0.38557189083213894:0.4817415730337079:0.4283249757916506\n",
      "0.48:0.38557189083213894:0.4817415730337079:0.4283249757916506\n",
      "0.49:0.37863836212639335:0.4803370786516854:0.4234673917207813\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_w2v_top('iac/iaccorpus_test.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n",
      "0.11:0.23310223852372472:0.48176718092566617:0.3141860744512863\n",
      "0.12:0.36229788161588183:0.4817671809256662:0.41357766557914477\n",
      "0.13:0.3362803785730571:0.48106591865357645:0.3958494209671909\n",
      "0.14:0.40535510867919067:0.48176718092566617:0.4402702767600973\n",
      "0.15:0.42687770638771794:0.48176718092566617:0.45266456033113883\n",
      "0.16:0.40516660876427724:0.4810659186535764:0.4398661543620851\n",
      "0.17:0.36156641360389297:0.4789621318373071:0.41206600584775693\n",
      "0.18:0.36156641360389297:0.4789621318373071:0.41206600584775693\n",
      "0.19:0.328553000009947:0.4761570827489481:0.38881788948585705\n",
      "0.2:0.328553000009947:0.4761570827489481:0.38881788948585705\n",
      "0.21:0.32267415460466087:0.4754558204768583:0.384441907243406\n",
      "0.22:0.32267415460466087:0.4754558204768583:0.384441907243406\n",
      "0.23:0.32267415460466087:0.4754558204768583:0.384441907243406\n",
      "0.24:0.3402608067131468:0.47545582047685836:0.39665485694270075\n",
      "0.25:0.3402608067131468:0.47545582047685836:0.39665485694270075\n",
      "0.26:0.32953998098118725:0.4740532959326788:0.3888024417667413\n",
      "0.27:0.3604535596313021:0.47475455820476853:0.4097828237097732\n",
      "0.28:0.3604535596313021:0.47475455820476853:0.4097828237097732\n",
      "0.29:0.3686768513792831:0.47335203366058903:0.4145081967246355\n",
      "0.3:0.3686768513792831:0.47335203366058903:0.4145081967246355\n",
      "0.31:0.3686768513792831:0.47335203366058903:0.4145081967246355\n",
      "0.32:0.3686768513792831:0.47335203366058903:0.4145081967246355\n",
      "0.33:0.3686768513792831:0.47335203366058903:0.4145081967246355\n",
      "0.34:0.3686768513792831:0.47335203366058903:0.4145081967246355\n",
      "0.35:0.3686768513792831:0.47335203366058903:0.4145081967246355\n",
      "0.36:0.3686768513792831:0.47335203366058903:0.4145081967246355\n",
      "0.37:0.3810684321384227:0.4740532959326788:0.4225053353248375\n",
      "0.38:0.3716126213113252:0.4726507713884993:0.4160857704816997\n",
      "0.39:0.3672855223242269:0.47194950911640954:0.41309100662522624\n",
      "0.4:0.3672855223242269:0.47194950911640954:0.41309100662522624\n",
      "0.41:0.36319505951834796:0.47124824684431976:0.41022567682064204\n",
      "0.42:0.36319505951834796:0.47124824684431976:0.41022567682064204\n",
      "0.43:0.3593214909138608:0.47054698457223004:0.4074805804437357\n",
      "0.44:0.3593214909138608:0.47054698457223004:0.4074805804437357\n",
      "0.45:0.3593214909138608:0.47054698457223004:0.4074805804437357\n",
      "0.46:0.3593214909138608:0.47054698457223004:0.4074805804437357\n",
      "0.47:0.35564720873654926:0.46984572230014027:0.4048473666830853\n",
      "0.48:0.35564720873654926:0.46984572230014027:0.4048473666830853\n",
      "0.49:0.35564720873654926:0.46984572230014027:0.4048473666830853\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_top('iac/iaccorpus.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n",
      "none\n",
      "0.12:0.2224238924181173:0.47058823529411764:0.3020728291316526\n",
      "0.13:0.2224238924181173:0.47058823529411764:0.3020728291316526\n",
      "0.14:0.48674188776634253:0.47198879551820727:0.47925183023877194\n",
      "0.15:0.5750570270302213:0.4733893557422969:0.5192938428020348\n",
      "0.16:0.4867045409713181:0.47198879551820727:0.47923372641237566\n",
      "0.17:0.4335518128266822:0.47058823529411764:0.4513114598357329\n",
      "0.18:0.4335518128266822:0.47058823529411764:0.4513114598357329\n",
      "0.19:0.35328933273025925:0.46638655462184875:0.40203548065563044\n",
      "0.2:0.35328933273025925:0.46638655462184875:0.40203548065563044\n",
      "0.21:0.35328933273025925:0.46638655462184875:0.40203548065563044\n",
      "0.22:0.35328933273025925:0.46638655462184875:0.40203548065563044\n",
      "0.23:0.35328933273025925:0.46638655462184875:0.40203548065563044\n",
      "0.24:0.39760414804219557:0.4677871148459384:0.4298497228703332\n",
      "0.25:0.39760414804219557:0.4677871148459384:0.4298497228703332\n",
      "0.26:0.3648911265010336:0.46498599439775906:0.4089021350998145\n",
      "0.27:0.3648911265010336:0.46498599439775906:0.4089021350998145\n",
      "0.28:0.3648911265010336:0.46498599439775906:0.4089021350998145\n",
      "0.29:0.3420204030256896:0.4621848739495798:0.39312514201638077\n",
      "0.3:0.3420204030256896:0.4621848739495798:0.39312514201638077\n",
      "0.31:0.3420204030256896:0.4621848739495798:0.39312514201638077\n",
      "0.32:0.3420204030256896:0.4621848739495798:0.39312514201638077\n",
      "0.33:0.3420204030256896:0.4621848739495798:0.39312514201638077\n",
      "0.34:0.3420204030256896:0.4621848739495798:0.39312514201638077\n",
      "0.35:0.3420204030256896:0.4621848739495798:0.39312514201638077\n",
      "0.36:0.3420204030256896:0.4621848739495798:0.39312514201638077\n",
      "0.37:0.3420204030256896:0.4621848739495798:0.39312514201638077\n",
      "0.38:0.33295718287314924:0.46078431372549017:0.3865778661380864\n",
      "0.39:0.32505339761083263:0.45938375350140054:0.3807169246666211\n",
      "0.4:0.32505339761083263:0.45938375350140054:0.3807169246666211\n",
      "0.41:0.32505339761083263:0.45938375350140054:0.3807169246666211\n",
      "0.42:0.32505339761083263:0.45938375350140054:0.3807169246666211\n",
      "0.43:0.31809145578001974:0.4579831932773109:0.37542919575923467\n",
      "0.44:0.31809145578001974:0.4579831932773109:0.37542919575923467\n",
      "0.45:0.31809145578001974:0.4579831932773109:0.37542919575923467\n",
      "0.46:0.31809145578001974:0.4579831932773109:0.37542919575923467\n",
      "0.47:0.31809145578001974:0.4579831932773109:0.37542919575923467\n",
      "0.48:0.31809145578001974:0.4579831932773109:0.37542919575923467\n",
      "0.49:0.31809145578001974:0.4579831932773109:0.37542919575923467\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_top('iac/iaccorpus_train.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n",
      "0.11:0.2437094476974205:0.49157303370786515:0.32586385661990314\n",
      "0.12:0.41259251041980316:0.4929775280898876:0.44921723830415605\n",
      "0.13:0.37010410715419284:0.49157303370786515:0.422276952965269\n",
      "0.14:0.37010410715419284:0.49157303370786515:0.422276952965269\n",
      "0.15:0.34446863626972646:0.49016853932584264:0.4046014081829335\n",
      "0.16:0.34446863626972646:0.49016853932584264:0.4046014081829335\n",
      "0.17:0.3148640187607436:0.48735955056179775:0.3825666373799114\n",
      "0.18:0.3148640187607436:0.48735955056179775:0.3825666373799114\n",
      "0.19:0.30547752808988765:0.48595505617977525:0.3751383308575018\n",
      "0.2:0.30547752808988765:0.48595505617977525:0.3751383308575018\n",
      "0.21:0.29809644061566:0.4845505617977528:0.36911352710689965\n",
      "0.22:0.29809644061566:0.4845505617977528:0.36911352710689965\n",
      "0.23:0.29809644061566:0.4845505617977528:0.36911352710689965\n",
      "0.24:0.29211882582669096:0.4831460674157303:0.3640976475175792\n",
      "0.25:0.29211882582669096:0.4831460674157303:0.3640976475175792\n",
      "0.26:0.29211882582669096:0.4831460674157303:0.3640976475175792\n",
      "0.27:0.35856755483509595:0.4845505617977528:0.412146546753549\n",
      "0.28:0.35856755483509595:0.4845505617977528:0.412146546753549\n",
      "0.29:0.39056712330069854:0.4845505617977528:0.43251215747924227\n",
      "0.3:0.39056712330069854:0.4845505617977528:0.43251215747924227\n",
      "0.31:0.39056712330069854:0.4845505617977528:0.43251215747924227\n",
      "0.32:0.39056712330069854:0.4845505617977528:0.43251215747924227\n",
      "0.33:0.39056712330069854:0.4845505617977528:0.43251215747924227\n",
      "0.34:0.39056712330069854:0.4845505617977528:0.43251215747924227\n",
      "0.35:0.39056712330069854:0.4845505617977528:0.43251215747924227\n",
      "0.36:0.39056712330069854:0.4845505617977528:0.43251215747924227\n",
      "0.37:0.4107437748923356:0.4859550561797753:0.4451952144615793\n",
      "0.38:0.4015093914561685:0.48455056179775285:0.4391386846515271\n",
      "0.39:0.4015093914561685:0.48455056179775285:0.4391386846515271\n",
      "0.4:0.4015093914561685:0.48455056179775285:0.4391386846515271\n",
      "0.41:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.42:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.43:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.44:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.45:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.46:0.39316100539066057:0.48314606741573035:0.4335334028684268\n",
      "0.47:0.38557189083213894:0.4817415730337079:0.4283249757916506\n",
      "0.48:0.38557189083213894:0.4817415730337079:0.4283249757916506\n",
      "0.49:0.38557189083213894:0.4817415730337079:0.4283249757916506\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val_wn_top('iac/iaccorpus_test.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def calc_val(file,v_threshold):\n",
    "    f = open (file,'r')\n",
    "    d_minval = dict()\n",
    "    d_predictedlabel = dict()\n",
    "    d_actuallabel = dict()\n",
    "    threshold = v_threshold\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "         \n",
    "# 2\tNOT_SARCASM\ttest\tbacking\t0.285714285714\n",
    "    for line in f:\n",
    "        words = line.strip().split('\\t')\n",
    "        if len(words) != 5:\n",
    "            continue\n",
    "            \n",
    "        id = words[0].strip()\n",
    "        label = words[1].strip()\n",
    "        d_actuallabel[id] = label.lower()\n",
    "\n",
    "        if id not in d_minval.keys():\n",
    "            d_minval[id] = '1'\n",
    "        \n",
    "        word1 = words[2].strip()\n",
    "        word2 = words[3].strip()\n",
    "        \n",
    "        if str(id) in answer.keys() and word1.strip() in answer[str(id)]:\n",
    "            val = words[4].strip()\n",
    "        elif str(id) not in answer.keys():\n",
    "            val = words[4].strip()\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        if words[4] == 'None' or words[4] == '-1':\n",
    "            continue\n",
    "        \n",
    "        if str(id) in answer.keys() and word1.strip() in answer[str(id)] and word1.strip().lower() in mo.vocab and word2.strip().lower() in mo.vocab:\n",
    "            val = str(mo.similarity(word1,word2))\n",
    "        elif str(id) not in answer.keys() and word1.strip().lower() in mo.vocab and word2.strip().lower() in mo.vocab:\n",
    "            val = str(mo.similarity(word1,word2))\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        if val == -1:\n",
    "            continue\n",
    "        f_val = float(val)\n",
    "        if (float(d_minval[id]) > f_val):\n",
    "            d_minval[id] = str(f_val)\n",
    "\n",
    "   \n",
    "    for id in d_minval.keys():\n",
    "        if (float(d_minval[id]) < threshold):\n",
    "            d_predictedlabel[id] = 'sarcasm'\n",
    "        else:\n",
    "            d_predictedlabel[id] = 'not_sarcasm'\n",
    "\n",
    "        #print(d_predictedlabel[id] +' '+d_actuallabel[id])\n",
    "        if d_predictedlabel[id] == 'sarcasm' and d_actuallabel[id] == 'sarcasm':\n",
    "            tp += 1\n",
    "        elif d_predictedlabel[id] == 'not_sarcasm' and d_actuallabel[id] != 'sarcasm':\n",
    "            tn += 1\n",
    "        elif d_predictedlabel[id] == 'sarcasm' and d_actuallabel[id] != 'sarcasm':\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "    if float(tp+fp)==0 or float(tp+fn) == 0 or float (tn+fn) == 0 or float(tn+fp) == 0:\n",
    "        return ('none')\n",
    "        \n",
    "\n",
    "    #print(str(tp)+' '+str(fp)+' '+str(tn)+' '+str(fn))\n",
    "    pprecision = float(tp)/float(tp+fp)\n",
    "    precall = float(tp)/float(tp+fn)\n",
    "    #pfscore = float(2*precision*recall)/float(precision+recall)\n",
    "    \n",
    "    nprecision = float(tn)/float(tn+fn)\n",
    "    nrecall = float(tn)/float(tn+fp)\n",
    "    #nfscore = float(2*precision*recall)/float(precision+recall)\n",
    "\n",
    "    total = tp + fp + fn + tn\n",
    "    aprecision = float(pprecision)*float(tp+fn)/float(total) + float(nprecision)*float(tn+fp)/float(total)\n",
    "    arecall = float(precall)*float(tp+fn)/float(total) + float(nrecall)*float(tn+fp)/float(total)\n",
    "    fscore = float(2*aprecision*arecall)/float(aprecision+arecall)\n",
    "    \n",
    "    return (str(threshold)+':'+str(aprecision)+':'+str(arecall)+':'+str(fscore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:0.6611133867616503:0.7773333333333333:0.7145283387469348\n",
      "0.11:0.6611133867616503:0.7773333333333333:0.7145283387469348\n",
      "0.12:0.6611133867616503:0.7773333333333333:0.7145283387469348\n",
      "0.13:0.6611526414907325:0.7764444444444445:0.7141754813467899\n",
      "0.14:0.6611526414907325:0.7764444444444445:0.7141754813467899\n",
      "0.15:0.6611526414907325:0.7764444444444445:0.7141754813467899\n",
      "0.16:0.6611526414907325:0.7764444444444445:0.7141754813467899\n",
      "0.17:0.6611526414907325:0.7764444444444445:0.7141754813467899\n",
      "0.18:0.6549151668402002:0.776:0.7103344506302951\n",
      "0.19:0.6499097222222222:0.7755555555555556:0.707195192386285\n",
      "0.2:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.21:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.22:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.23:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.24:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.25:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.26:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.27:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.28:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.29:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.3:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.31:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.32:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.33:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.34:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.35:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.36:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.37:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.38:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.39:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.4:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.41:0.6663094725729831:0.7759999999999999:0.7169836440084407\n",
      "0.42:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.43:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.44:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.45:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.46:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.47:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.48:0.6800212491311688:0.7764444444444444:0.7250410680059813\n",
      "0.49:0.6800212491311688:0.7764444444444444:0.7250410680059813\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.5,0.01):\n",
    "    print(calc_val('tweets/tweets.o',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
